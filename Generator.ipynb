{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, autograd, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    #lines = open('data/eng-heb.txt').read().strip().split('\\n')\n",
    "    lines = open('/Users/kfirbar/Documents/research/group47/tweets-ny.txt').read().strip().split('\\n')\n",
    "    english_lines = [l.split('\\t')[0].lower().strip() for l in lines]\n",
    "    return english_lines\n",
    "\n",
    "data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i’m opening up a store for all vintage cozy &amp; designer clothing.\n"
     ]
    }
   ],
   "source": [
    "print random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = 0\n",
    "MAX_SEQ_LEN = 40\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.char2id = {}\n",
    "        self.id2char = {}\n",
    "        self.char2count = {}\n",
    "        self.n_chars = 1\n",
    "        \n",
    "        \n",
    "    def index_sentence(self, sentence):\n",
    "        for c in sentence:\n",
    "            self.index_char(c)\n",
    "        \n",
    "    \n",
    "    def index_char(self, c):\n",
    "        if c not in self.char2id:\n",
    "            self.char2id[c] = self.n_chars\n",
    "            self.char2count[c] = 1\n",
    "            self.id2char[self.n_chars] = c\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[c] += 1\n",
    "            \n",
    "            \n",
    "def prepare_data(data):\n",
    "    lang = Lang()\n",
    "    for sentence in data:\n",
    "        if len(sentence) <= MAX_SEQ_LEN:\n",
    "            lang.index_sentence(sentence)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence2variable(sentence):\n",
    "    indexes = [lang.char2id[c] for c in sentence]\n",
    "    input_var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    target_var = Variable(torch.LongTensor(indexes[1:]).view(-1, 1))\n",
    "    return input_var, target_var\n",
    "\n",
    "def data2variables(data):\n",
    "    variables = [sentence2variable(s) for s in data if len(s) <= MAX_SEQ_LEN]\n",
    "    return variables\n",
    "\n",
    "data_variables = data2variables(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextGen(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(TextGen, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, char_input, hidden):\n",
    "        seq_len = len(char_input)\n",
    "        embedded = self.embedding(char_input).view(seq_len, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.out(output.view(1, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(self.n_layers, 1, self.hidden_size)),\n",
    "                Variable(torch.zeros(self.n_layers, 1, self.hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 800\n",
    "n_layers = 6\n",
    "\n",
    "model = TextGen(lang.n_chars, hidden_size, lang.n_chars, 1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_seq(model, optimizer, criterion, input_var, target_var):\n",
    "    optimizer.zero_grad()\n",
    "    seq_len = len(input_var.data)\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    for o in range(seq_len):\n",
    "        output, hidden = model(input_var[o], hidden)\n",
    "        loss += criterion(output.view(-1).unsqueeze(0), target_var[o])\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), 5.0)\n",
    "    optimizer.step()\n",
    "    return loss.data[0] / seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Current Loss = 3.9693\n",
      "Epoch 200 Current Loss = 3.1655\n",
      "Epoch 300 Current Loss = 2.9400\n",
      "Epoch 400 Current Loss = 2.7679\n",
      "Epoch 500 Current Loss = 2.6691\n",
      "Epoch 600 Current Loss = 2.5352\n",
      "Epoch 700 Current Loss = 2.6078\n",
      "Epoch 800 Current Loss = 2.4188\n",
      "Epoch 900 Current Loss = 2.5055\n",
      "Epoch 1000 Current Loss = 2.3548\n",
      "Epoch 1100 Current Loss = 2.2732\n",
      "Epoch 1200 Current Loss = 2.1008\n",
      "Epoch 1300 Current Loss = 2.2345\n",
      "Epoch 1400 Current Loss = 2.2274\n",
      "Epoch 1500 Current Loss = 2.3534\n",
      "Epoch 1600 Current Loss = 2.2043\n",
      "Epoch 1700 Current Loss = 2.2169\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20000\n",
    "print_every = 100\n",
    "loss = 0\n",
    "for e in range(1, n_epochs + 1):\n",
    "    pair = random.choice(data_variables)\n",
    "    input_var = pair[0]\n",
    "    target_var = pair[1]\n",
    "    loss += train_seq(model, optimizer, criterion, input_var, target_var)\n",
    "    \n",
    "    if e % print_every == 0:\n",
    "        loss = loss / print_every\n",
    "        print 'Epoch %d Current Loss = %.4f' % (e, loss)\n",
    "        loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(model, start_string, temperature, max_len):\n",
    "    hidden = model.init_hidden()\n",
    "    start_var,_ = sentence2variable(start_string)\n",
    "    for i in range(len(start_string) - 1):\n",
    "        _, hidden = model(start_var[i], hidden)\n",
    "    \n",
    "    str = start_string\n",
    "    out, hidden = model(start_var[-1], hidden)\n",
    "    out_dist = out.data.view(-1).div(temperature).exp()\n",
    "    new_c = lang.id2char[torch.multinomial(out_dist, 1)[0]]\n",
    "    str += new_c\n",
    "    for i in range(max_len):\n",
    "        new_c_var, _ = sentence2variable(new_c)\n",
    "        out, hidden = model(new_c_var, hidden)\n",
    "        out_dist = out.data.view(-1).div(temperature).exp()\n",
    "        char_id = torch.multinomial(out_dist, 1)[0]\n",
    "        if char_id == EOS_TOKEN:\n",
    "            return str\n",
    "        new_c = lang.id2char[char_id]\n",
    "        str += new_c\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n",
      "i hate lkkkkkkk\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print generate(model, 'i hate ', 0.01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am at life.\n",
      "i am at lights.\n",
      "i am at will got and marking name\n",
      "i am at the strip\n",
      "i am at placom\n",
      "i am at sich musnc\n",
      "i am at lifgeting assours air this is a my shuts\n",
      "i am at is mach y a get to me\n",
      "i am at stunting\n",
      "i am at will get to me\n",
      "i am at dou this night prns\n",
      "i am at clasing serving\n",
      "i am at urs get on is america\n",
      "i am at sunch 57\n",
      "i am at will arrears\n",
      "i am at is happening!\n",
      "i am at live to mether.\n",
      "i am at raing need on\n",
      "i am at sich you to tere!!\n",
      "i am at to got https://t.co/si4lizmnrf\n",
      "i am at like tapl\n",
      "i am at usget #897\n",
      "i am at still\n",
      "i am at ungels\n",
      "i am at iscims souck a dj. #2017in4words\n",
      "i am at suchos\n",
      "i am at light\n",
      "i am at life.\n",
      "i am at using to you too https://t.co/dtpuajpzn\n",
      "i am at life.\n",
      "i am at such able\n",
      "i am at clasic so leadust\n",
      "i am at ussed but\n",
      "i am at s lightt!!!!\n",
      "i am at sich . #prns\n",
      "i am at ust a be #prnc\n",
      "i am at lighttra\n",
      "i am at swith have take.\n",
      "i am at luck https://t.co/az5vmnmfgl\n",
      "i am at uch my get\n",
      "i am at shit that\n",
      "i am at is me pacito\n",
      "i am at still dousing everyone is freedon\n",
      "i am at clasing - action\n",
      "i am at luths for my soll\"\n",
      "i am at scute\n",
      "i am at suck https://t.co/wzc7rlxd6w\n",
      "i am at cuth\n",
      "i am at us whow to happy to b0 back to #prns\n",
      "i am at us a be a thing\n",
      "i am at such you\n",
      "i am at rich my feet\n",
      "i am at sumph\n",
      "i am at life.\n",
      "i am at lime the reaved.\n",
      "i am at is a chots on the storl\n",
      "i am at is 24/7 https://t.co/dwickeugt6\n",
      "i am at ugming my my!\n",
      "i am at cutumin\n",
      "i am at thing und\n",
      "i am at uch my me at ?\n",
      "i am at unched better\n",
      "i am at successful at life.\n",
      "i am at shit that with event the nights\n",
      "i am at ust stack something\n",
      "i am at c” https://t.co/v7ibichvb\n",
      "i am at sick mor\n",
      "i am at life.\n",
      "i am at and is liker!\n",
      "i am at sucte\n",
      "i am at ug af it dousing loses reggin\n",
      "i am at cill awit?\n",
      "i am at us choming today\n",
      "i am at clasting\n",
      "i am at selfie https://t.co/kpu9o2t8a\n",
      "i am at is a bigget rip.\n",
      "i am at us https://t.co/albqg3kzv\n",
      "i am at rich my an e0\n",
      "i am at lany to you tarke.\n",
      "i am at unction\n",
      "i am at life.\n",
      "i am at music size s…\n",
      "i am at locoming today 🔥💨\n",
      "i am at scurts\n",
      "i am at successful at life.\n",
      "i am at is a blithfin!\n",
      "i am at cart\n",
      "i am at suchom\n",
      "i am at life.\n",
      "i am at like craip to me\n",
      "i am at life.\n",
      "i am at usinessure dayson\n",
      "i am at sucches full at life.\n",
      "i am at us whould that kide strip\n",
      "i am at usceas.\n",
      "i am at snotuin every day.\n",
      "i am at laction.\n",
      "i am at usins thear is lought\n",
      "i am at uscest fung\n",
      "i am at up 57% https://t.co/hrcqr2f3a\n",
      "i am at sick #prns\n",
      "i am at us chope saturday 7mp\n",
      "i am at cutting mend a steel\n",
      "i am at lite\n",
      "i am at is hazppy 😁\n",
      "i am at such popl\n",
      "i am at lithan.\n",
      "i am at is a charts\n",
      "i am at clouds\n",
      "i am at is shith https://t.co/abfu4pzjs\n",
      "i am at thot.\n",
      "i am at us that haivs\n",
      "i am at uster some\n",
      "i am at suck https://t.co/abefxsdesx\n",
      "i am at shit https://t.co/9pzgn6fm7m\n",
      "i am at ustice tongal\n",
      "i am at sick much\n",
      "i am at success\n",
      "i am at life.\n",
      "i am at legain\n",
      "i am at in los anders\n",
      "i am at money https://t.co/yczuy0pkfk\n",
      "i am at us the ast some the press bet to #prns\n",
      "i am at louthing\n",
      "i am at cute\n",
      "i am at lifetion.\n",
      "i am at unsomethif.\n",
      "i am at clutsn carts\n",
      "i am at life\n",
      "i am at is my sanes\n",
      "i am at sting\n",
      "i am at hackituan\n",
      "i am at rucho.\n",
      "i am at usch\n",
      "i am at suches\n",
      "i am at thing bumb\n",
      "i am at sicki #201744 how\n",
      "i am at uncher to me\n",
      "i am at uncom yuck\n",
      "i am at is shit https://t.co/gh0y7ib4j\n",
      "i am at life.\n",
      "i am at music .\n",
      "i am at music, . #prns\n",
      "i am at us a mire japd stating\n",
      "i am at successful at life.\n",
      "i am at is a wait!!!!!!!!!! #ningrsometso #prns\n",
      "i am at light!\n",
      "i am at clouds\n",
      "i am at life!\n",
      "i am at suches\n",
      "i am at cutting broken up #nych\n",
      "i am at succos\n",
      "i am at luck u\n",
      "i am at light!!\n",
      "i am at inct bust than https://t.co/ywi0rvhqv\n",
      "i am at us a clouds\n",
      "i am at is friends.\n",
      "i am at life.\n",
      "i am at cutla\n",
      "i am at liker my #tels\n",
      "i am at usicy of the struelb\n",
      "i am at succh sang\n",
      "i am at bulties lol\n",
      "i am at usines.\n",
      "i am at sucte?\n",
      "i am at successful at life.\n",
      "i am at sich life\n",
      "i am at music ston\n",
      "i am at us a mo happy borthan\n",
      "i am at bule ? https://t.co/ojkefydpd8\n",
      "i am at usife!\n",
      "i am at will amf tryan.\n",
      "i am at cutos\n",
      "i am at is a siction\n",
      "i am at that is a butuh up #never\n",
      "i am at uster\n",
      "i am at clouds\n",
      "i am at light\n",
      "i am at uster.\n",
      "i am at clouds\n",
      "i am at sich feel\n",
      "i am at life today\n",
      "i am at is meson the stocart\n",
      "i am at lust nawt.\n",
      "i am at turke.\n",
      "i am at shit https://t.co/qgn6p07vhxx\n",
      "i am at usin!!!\n",
      "i am at shit https://t.co/ptsnocjutw\n",
      "i am at a in this\n",
      "i am at us the busting lmy aft\n",
      "i am at thanks!\n",
      "i am at uch happy to best a there #prns\n",
      "i am at is stunrting\n",
      "i am at outh plasso.\n",
      "i am at cuts me\n",
      "i am at uplarine.\n",
      "i am at uchosh\n",
      "i am at like crain\n",
      "i am at action.\n",
      "i am at cuts https://t.co/ngin0noppat\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print generate(model, 'i am at ', 0.8, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
